# scripts/download_parallel.py (æœ€ç»ˆä¾¦å¯Ÿç‰ˆ)

import os
import json
# import baostock as bs # æˆ‘ä»¬å…ˆä¸å¯¼å…¥ï¼Œä¸“æ³¨äºèµ„é‡‘æµ
import requests
import pandas as pd
from tqdm import tqdm
import time
import sys

# --- é…ç½® ---
MONEYFLOW_OUTPUT_DIR = "data_slice/moneyflow"
SINA_API_HISTORY = "https://vip.stock.finance.sina.com.cn/quotes_service/api/json_v2.php/MoneyFlow.ssl_qsfx_lscjfb?page={page}&num=50&sort=opendate&asc=0&daima={code}"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://vip.stock.finance.sina.com.cn/'
}
TASK_INDEX = int(os.getenv("TASK_INDEX", 0))
os.makedirs(MONEYFLOW_OUTPUT_DIR, exist_ok=True)


def download_fundflow(code):
    """(å¼•æ“B) ä»æ–°æµªè´¢ç»è·å–èµ„é‡‘æµæ•°æ® - ä¸¥æ ¼æ¨¡å¼"""
    all_data_list = []
    page = 1
    code_for_api = code.replace('.', '')
    print(f"\n  -> Attempting to download fund flow for {code}...")
    
    # --- (è¿™æ˜¯å”¯ä¸€çš„ã€å…³é”®çš„ä¿®æ­£) ---
    # æˆ‘ä»¬å°†å¾ªç¯æ”¾åœ¨ try å—å†…éƒ¨ï¼Œå¹¶ä¸”è®©å¤±è´¥ä¼ é€’å‡ºå»
    try:
        while page <= 150:
            target_url = SINA_API_HISTORY.format(page=page, num=50, code=code_for_api)
            
            # å¢åŠ æ‰“å°ï¼Œçœ‹çœ‹æˆ‘ä»¬è¯·æ±‚çš„ URL æ˜¯ä»€ä¹ˆ
            if page <= 2: # åªæ‰“å°å‰ä¸¤é¡µçš„URL
                print(f"     Requesting page {page}: {target_url}")

            response = requests.get(target_url, headers=HEADERS, timeout=45)
            response.raise_for_status() # è¿™æ˜¯å…³é”®ï¼å¦‚æœçŠ¶æ€ç ä¸æ˜¯2xxï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
            response.encoding = 'gbk'
            data = response.json()
            
            if not data:
                print(f"     Page {page} returned empty data. Ending pagination.")
                break
            
            all_data_list.extend(data)
            
            if len(data) < 50:
                print(f"     Page {page} is the last page ({len(data)} records).")
                break
                
            page += 1
            time.sleep(0.3)
            
    except Exception as e:
        print(f"\n  -> âŒ CRITICAL FAILURE during download for {code} on page {page}: {e}")
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸»å¾ªç¯çš„ except å—èƒ½æ•è·åˆ°ï¼Œå¹¶è®©æ•´ä¸ªè„šæœ¬å¤±è´¥
        raise e
    # ------------------------------------------

    if all_data_list:
        df = pd.DataFrame(all_data_list)
        df.to_parquet(f"{MONEYFLOW_OUTPUT_DIR}/{code}.parquet", index=False)
        print(f"  -> âœ… Success for {code}, saved {len(df)} records.")

def main():
    task_file = f"tasks/task_slice_{TASK_INDEX}.json"
    try:
        with open(task_file, "r", encoding="utf-8") as f:
            subset = json.load(f)
    except FileNotFoundError:
        print(f"âŒ è‡´å‘½é”™è¯¯: æœªæ‰¾åˆ°ä»»åŠ¡åˆ†ç‰‡æ–‡ä»¶ {task_file}ï¼"); sys.exit(1)
        
    if not subset: print("ğŸŸ¡ æœ¬åˆ†åŒºä»»åŠ¡åˆ—è¡¨ä¸ºç©ºã€‚"); return
    
    print(f"ğŸ“¦ åˆ†åŒº {TASK_INDEX + 1}ï¼Œè´Ÿè´£ {len(subset)} æ”¯è‚¡ç¥¨ (ä»…ä¸‹è½½èµ„é‡‘æµ)ã€‚")
    
    for s in tqdm(subset, desc=f"åˆ†åŒº {TASK_INDEX + 1} æ€»ä½“è¿›åº¦"):
        code = s["code"]
        name = s.get("name", "")
        
        try:
            download_fundflow(code)
        except Exception as e:
            # æ•è·ä» download_fundflow æŠ›å‡ºçš„å¼‚å¸¸
            print(f"\n" + "="*60)
            print(f"âŒ è„šæœ¬å› å¤„ç† {name} ({code}) æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯è€Œç»ˆæ­¢ã€‚")
            print(f"   æ ¹æœ¬åŸå› : {e}")
            print("="*60)
            sys.exit(1) # <--- è®©æ•´ä¸ª job å¤±è´¥ï¼

    print(f"\nâœ… åˆ†åŒº {TASK_INDEX + 1} ä»»åŠ¡å®Œæˆã€‚")

if __name__ == "__main__":
    main()
