# scripts/collect_and_merge.py

import pandas as pd
import glob
import os
from tqdm import tqdm
import shutil
import json

# --- é…ç½® ---
INPUT_BASE_DIR = "all_data"
OUTPUT_KDATA_DIR = "final_kdata"
OUTPUT_MONEYFLOW_DIR = "final_moneyflow"
QC_REPORT_FILE = "data_quality_report.json"

# run_quality_check å‡½æ•°ä¿æŒä¸å˜

def collect_and_merge_data(data_type, output_dir):
    print("\n" + "="*50)
    print(f"ğŸš€ å¼€å§‹æ”¶é›†å’Œå¤„ç† {data_type} æ•°æ®...")
    
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
    os.makedirs(output_dir)

    # (å…³é”®ä¿®æ­£) æœç´¢è·¯å¾„ä¸å†åŒ…å« "data_slice"
    search_pattern = os.path.join(INPUT_BASE_DIR, "data_part_*", data_type, "*.parquet")
    file_list = glob.glob(search_pattern)
    
    if not file_list:
        print(f"âš ï¸ æœªæ‰¾åˆ°ä»»ä½• {data_type} çš„ Parquet æ–‡ä»¶ã€‚")
        return None

    print(f"ğŸ“¦ å…±æ‰¾åˆ° {len(file_list)} ä¸ª {data_type} æ–‡ä»¶ï¼Œå¼€å§‹æ”¶é›†...")
    all_dfs = []
    for src_path in tqdm(file_list, desc=f"æ”¶é›†ä¸­ ({data_type})"):
        try:
            filename = os.path.basename(src_path)
            dest_path = os.path.join(output_dir, filename)
            shutil.copy2(src_path, dest_path)
            all_dfs.append(pd.read_parquet(dest_path))
        except Exception as e:
            print(f"\nâš ï¸ å¤„ç†æ–‡ä»¶ {src_path} å¤±è´¥: {e}")
            
    print(f"âœ… å…¨éƒ¨ {len(file_list)} ä¸ªæ–‡ä»¶å·²æ”¶é›†åˆ° '{output_dir}' ç›®å½•ã€‚")
    
    if all_dfs:
        return pd.concat(all_dfs, ignore_index=True)
    return None

def main():
    kdata_df = collect_and_merge_data("kdata", OUTPUT_KDATA_DIR)
    moneyflow_df = collect_and_merge_data("moneyflow", OUTPUT_MONEYFLOW_DIR)
    
    # run_quality_check(kdata_df, moneyflow_df) # è´¨æ£€å¯ä»¥åç»­å†å®Œå–„

if __name__ == "__main__":
    main()
```**æ³¨æ„**ï¼šä¸ºç¡®ä¿ `collect_and_merge.py` èƒ½å…ˆè·‘é€šï¼Œæˆ‘æš‚æ—¶æ³¨é‡Šæ‰äº† `run_quality_check` çš„è°ƒç”¨ï¼Œæ‚¨å¯ä»¥åç»­å†æ‰“å¼€ã€‚

---

### **è¡ŒåŠ¨èµ·æ¥**
1.  **æ›´æ–°è„šæœ¬**: å°†æ‚¨ä»“åº“ä¸­çš„è¿™3ä¸ªè„šæœ¬ï¼Œå®Œå…¨æ›¿æ¢ä¸ºä¸Šé¢çš„æœ€ç»ˆç‰ˆæœ¬ã€‚
2.  **å·¥ä½œæµæ–‡ä»¶**: æ‚¨ç°æœ‰çš„ `.github/workflows/main_pipeline.yml` **æ— éœ€ä»»ä½•ä¿®æ”¹**ã€‚
3.  **è¿è¡Œ**ã€‚

è¿™æ¬¡ï¼Œ`download_parallel.py` ä¼šæ­£ç¡®åœ°ä¸²è¡Œä¸‹è½½ä¸¤ç§æ•°æ®ï¼Œ`collect_and_merge.py` ä¹Ÿèƒ½æ­£ç¡®åœ°æ‰¾åˆ°å¹¶æ”¶é›†å®ƒä»¬ã€‚æ‚¨çš„æ•°æ®ç®¡é“å°†çœŸæ­£åœ°å®Œæ•´è¿è¡Œèµ·æ¥ã€‚
